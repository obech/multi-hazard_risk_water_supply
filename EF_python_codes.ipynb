{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import rioxarray\n",
    "import networkx as nx\n",
    "from shapely import wkt\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import Point\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import genextreme as gev\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from copulas.multivariate import GaussianMultivariate\n",
    "from scipy.interpolate import interp1d\n",
    "import statsmodels.distributions.empirical_distribution as edf\n",
    "import seaborn as sns\n",
    "from scipy.stats import genextreme as gev\n",
    "from pathos.multiprocessing import ProcessPool, cpu_count\n",
    "import statsmodels.api as sm\n",
    "import shapely\n",
    "from shapely.ops import nearest_points\n",
    "import multiprocessing as mp\n",
    "import geopandas as gpd\n",
    "from shapely.ops import split, snap\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import LineString, shape\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "import itertools\n",
    "from shapely.geometry import mapping\n",
    "import matplotlib.colors as clr\n",
    "from scipy.stats.mstats import gmean\n",
    "from copulalib.copulalib import Copula\n",
    "import xarray as xr\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each figure (Figure 1/2/3)\n",
    "## analysis modules\n",
    "# flood depth intersection\n",
    "# wind copula\n",
    "# for flood/wind intersection and disruption per system\n",
    "# uncertainty\n",
    "# streamflow random regression\n",
    "# for drought water balance and disruption per system\n",
    "# for aed per system\n",
    "# for utility level risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset database - Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major_cities = dataframe of major cities in Jamaica\n",
    "# island = geodataframe of Jamaica outline\n",
    "# parishes = geodataframe of parishes in Jamaica \n",
    "# pipelines_NWC = geodataframe of National Water Comission potable pipelines\n",
    "# potable_facilities_NWC = geodataframe of National Water Comission potable assets \n",
    "\n",
    "plants = potable_facilities_NWC[potable_facilities_NWC['asset_type'].isin(['Filter Plant','River Source','Treatment Plant'])]\n",
    "pumps = potable_facilities_NWC[potable_facilities_NWC['asset_type'].isin(['Spring','Pump Station','Relift Station','Sump','Booster Station'])]\n",
    "wells = potable_facilities_NWC[potable_facilities_NWC['asset_type'].isin(['Production Well'])]\n",
    "other = potable_facilities_NWC[potable_facilities_NWC['asset_type'].isin(['Catchment', 'Reservoir', 'Storage Tank'])]\n",
    "dams = potable_facilities_NWC[potable_facilities_NWC['LOCATION_x'].isin(['Mona Dam', 'Hermitage Dam'])]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17,7), linewidth=0.05)    \n",
    "island.plot(ax=ax, color='whitesmoke', edgecolor='black', linewidth=0.5)\n",
    "parishes.plot(ax=ax, color='none', edgecolor='black', linewidth=0.5)\n",
    "pipelines_NWC.plot(ax=ax, color='gold', edgecolor='gold', linewidth=0.4, alpha=0.8)\n",
    "\n",
    "ax.scatter(plants['lon'], plants['lat'], color='cyan', marker = 's', edgecolor='k', linewidth=0.5)\n",
    "ax.scatter(pumps['lon'], pumps['lat'], color='navy', marker = '^', edgecolor='k', linewidth=0.5)\n",
    "ax.scatter(wells['lon'], wells['lat'], color='mediumorchid', marker = 'd', edgecolor='k', linewidth=0.5)\n",
    "ax.scatter(other['lon'], other['lat'], color='lightgrey', marker = 'o', edgecolor='k', linewidth=0.5, s=5)\n",
    "ax.scatter(dams['lon'], dams['lat'], color='r', marker = 's', s=20, edgecolor='k', linewidth=0.5)\n",
    "\n",
    "ax.set_ylim(600000,720000) \n",
    "ax.set_xlim(600000,850000)    \n",
    "ax.set_title('Potable supply systems')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "pipelines = mpatches.Patch(color='gold', label='Pipelines')\n",
    "plants = mpatches.Patch(color='cyan', label='Water treatment plants')\n",
    "pumps = mpatches.Patch(color='navy', label='Pumping stations')\n",
    "wells = mpatches.Patch(color='mediumorchid', label='Wells')\n",
    "dams = mpatches.Patch(color='red', label='Dams')\n",
    "\n",
    "ax.scatter(major_cities['X'], major_cities['Y'], s=30, color='k', marker = 'o', edgecolor='k', linewidth=0.5) #major_cities['pop']*10\n",
    "for i, txt in enumerate(major_cities['name']):\n",
    "    ax.annotate(txt, (major_cities['X'][i]+500, major_cities['Y'][i]-1000),c='k', fontsize=10, bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"None\", alpha=0.8)) #, rotation=45\n",
    "\n",
    "major_cities = mlines.Line2D([], [], color='k', marker='o', linestyle='None',\n",
    "                          markersize=10, label='Major cities')\n",
    "pipelines = mlines.Line2D([], [], color='gold', marker='None', linestyle='-',\n",
    "                          markersize=10, label='Pipelines')\n",
    "plants = mlines.Line2D([], [], color='cyan', marker='s', linestyle='None',\n",
    "                          markersize=10, label='Water treatment plants')\n",
    "pumps = mlines.Line2D([], [], color='navy', marker='^', linestyle='None',\n",
    "                          markersize=10, label='Pumping stations')\n",
    "wells = mlines.Line2D([], [], color='mediumorchid', marker='^', linestyle='None',\n",
    "                          markersize=10, label='Wells')\n",
    "dams = mlines.Line2D([], [], color='red', marker='s', linestyle='None',\n",
    "                          markersize=10, label='Dams')\n",
    "other = mlines.Line2D([], [], color='lightgrey', marker='o', linestyle='None',\n",
    "                          markersize=5, label='Other')\n",
    "households = mpatches.Patch(color='grey', label='households')\n",
    "\n",
    "ax.legend(handles=[pipelines,plants,pumps,wells,other,dams,major_cities], loc='upper right') #households\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "plt.rcParams['savefig.facecolor']='white'\n",
    "\n",
    "ax.set_facecolor(('paleturquoise'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood and wind intersection per return period map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme_wind_return_period_maps = raster of wind speeds per return period per climate change scenario \n",
    "# extreme_fluvial_flood_return_period_maps = raster of flood depth per return period per climate change scenario      \n",
    "# extreme_pluvial_flood_return_period_maps = raster of flood depth per return period per climate change scenario      \n",
    "\n",
    "# potable_facilities_NWC = geodataframe of National Water Comission potable assets \n",
    "\n",
    "for hazard in [extreme_wind_rp_maps, extreme_fluvial_flood_rp_maps, extreme_pluvial_flood_rp_maps]:\n",
    "    for col in list(hazard.columns):      \n",
    "        potable_facilities_NWC.index = range(len(pts))\n",
    "        coords = [(x,y) for x, y in zip(potable_facilities_NWC.X, potable_facilities_NWC.Y)]\n",
    "\n",
    "        potable_facilities_NWC[col] = [x for x in extreme_wind_return_period_maps.sample(coords)]\n",
    "        potable_facilities_NWC[col] = potable_facilities_NWC.apply(lambda x: x[col][0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind and flood copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_wind_per_hurr = netcdf of maximum wind speed per hurricane track.id extracted from ERA5 layers\n",
    "# ObsEventRP = flood return period per hurricane track.id simulated by JBA flood model\n",
    "\n",
    "ObsEventRP = ObsEventRP.merge(max_wind_per_hurr, on=['track.id','event.id','op.id'])[['event.id','track.id','op.id','rp', 'max_wind', 'start.year']].drop_duplicates()\n",
    "ObsEventRP = ObsEventRP.sort_values(by=['max_wind'], ascending=False)\n",
    "num_events = ObsEventRP.shape[0]\n",
    "ObsEventRP['start.year'] = pd.to_numeric(ObsEventRP['start.year'], errors='coerce')\n",
    "max_year = ObsEventRP['start.year'].max()\n",
    "min_year = ObsEventRP['start.year'].min()\n",
    "num_years = iter_char_2_max -  iter_char_2_min\n",
    "ObsEventRP['rank_wind'] = np.linspace(1, num_events+1, num_events)\n",
    "ObsEventRP['rp_wind'] = 1/(ObsEventRP['rank_wind']/num_years)\n",
    "ObsEventRP = ObsEventRP.sort_values(by=['rp'], ascending=False)\n",
    "ObsEventRP['rank_flood'] = np.linspace(1, num_events+1, num_events)\n",
    "ObsEventRP['rp_flood'] = 1/(ObsEventRP['rank_flood']/num_years)\n",
    "ObsEventRP = ObsEventRP[['rp_flood','rp_wind']]\n",
    "\n",
    "gaussian = GaussianMultivariate()\n",
    "gaussian.fit(ObsEventRP)\n",
    "synthetic_data_df = gaussian.sample(10000)\n",
    "synthetic_data_df['model'] = ['Gaussian']*synthetic_data_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample flood and wind return period and associated hazard varialbe per asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimEventRP = # dataframe of JBA synthetic flood events and affected zones under baseline conditions\n",
    "SimEventRP_rcp26_2080s = # dataframe of synthetic flood events and affected zones under rcp2.6 emissions end of century scenario \n",
    "SimEventRP_rcp45_2080s = # dataframe of synthetic flood events and affected zones under rcp4.5 emissions end of century scenario \n",
    "SimEventRP_rcp85_2080s = # dataframe of synthetic flood events and affected zones under rcp8.5 emissions end of century scenario \n",
    "\n",
    "synthetic_data_df = # sampled wind event conditional flood event \n",
    "\n",
    "damage_curves_flood_pump = # flood damage curve for pumping stations \n",
    "damage_curves_flood_wtw = # flood damage curve for water treatment plants\n",
    "damage_curves_flood_well = # flood damage curve for wells\n",
    "damage_curves_wind = # wind damage curve for all water assets\n",
    "\n",
    "for cc in [SimEventRP,SimEventRP_rcp26_2080s,SimEventRP_rcp45_2080s,SimEventRP_rcp85_2080s]:\n",
    "    for i in cc['event.id'].drop_duplicates().to_list(): # pluvial and fluvial\n",
    "        sub = cc[cc['event.id']==i]\n",
    "        for zone in sub['zone']:\n",
    "            zone_gdf = sub[sub['zone']==zone]\n",
    "            event_zone_flood_rp = zone_gdf['rp']\n",
    "            synthetic_data_df['rp_flood_diff'] = abs(synthetic_data_df[synthetic_data_df['rp_flood']-event_zone_flood_rp])\n",
    "            event_zone_wind_rp = synthetic_data_df[synthetic_data_df['rp_flood_diff']==synthetic_data_df['rp_flood_diff'].min()]['rp_wind'].values[0]    \n",
    "            affected_assets = potable_facilities_NWC.rio.clip(zone_gdf.geometry.apply(mapping),crs=zone_gdf.geometry.crs)\n",
    "            affected_assets_rp = potable_facilities_NWC.merge(affected_assets, on='node.id')\n",
    "            for asset in affected_assets_rp['node.id']:\n",
    "                asset_sub = affected_assets_rp[affected_assets_rp['node.id']==asset]\n",
    "                # where rp_min and rp_max are the return periods below and above event_zone_flood_rp\n",
    "                # flood_depth_rp_min and flood_depth_rp_max are the flood depths associated with rp_min and rp_max extracted from the return period maps\n",
    "                # flood_depth_rp_min and flood_depth_rp_max are the flood depths associated with rp_min and rp_max extracted from the return period maps\n",
    "                \n",
    "                asset_sub['flood_depth']  = asset_sub['flood_depth_rp_min'] + (np.log(event_zone_flood_rp) - np/log(rp_min))/(np.log(rp_max) - np.log(rp_min)) * (df['flood_depth_rp_max'] - df['flood_depth_rp_min'])\n",
    "                # same as above for wind using GEV scaling \n",
    "                if asset_sub['asset_type'].isin(['Spring','Pump Station','Relift Station','Sump','Booster Station']):\n",
    "                    asset_sub['flood_damage_frac'] = damage_curves_flood_pump['dam_frac_rp_min'] + (asset_sub['flood_depth'] - asset_sub['flood_depth_rp_min'])/(asset_sub['flood_depth_rp_max'] - asset_sub['flood_depth_rp_min']) * (damage_curves_flood_pump['dam_frac_rp_max'] - damage_curves_flood_pump['dam_frac_rp_min'])\n",
    "                elif asset_sub['asset_type'].isin(['Filter Plant','River Source','Treatment Plant']):\n",
    "                    asset_sub['flood_damage_frac'] = damage_curves_flood_wtw['dam_frac_rp_min'] + (asset_sub['flood_depth'] - asset_sub['flood_depth_rp_min'])/(asset_sub['flood_depth_rp_max'] - asset_sub['flood_depth_rp_min']) * (damage_curves_flood_wtw['dam_frac_rp_max'] - damage_curves_flood_wtw['dam_frac_rp_min'])\n",
    "                elif asset_sub['asset_type'].isin(['Production Well']):\n",
    "                    asset_sub['flood_damage_frac'] = damage_curves_flood_well['dam_frac_rp_min'] + (asset_sub['flood_depth'] - asset_sub['flood_depth_rp_min'])/(asset_sub['flood_depth_rp_max'] - asset_sub['flood_depth_rp_min']) * (damage_curves_flood_well['dam_frac_rp_max'] - damage_curves_flood_well['dam_frac_rp_min'])                   \n",
    "                else:\n",
    "                    asset_sub['flood_damage_frac'] = 'nan'\n",
    "                \n",
    "                asset_sub['wind_damage_frac'] = damage_curves_wind['dam_frac_rp_min'] + (asset_sub['flood_depth'] - asset_sub['flood_depth_rp_min'])/(asset_sub['flood_depth_rp_max'] - asset_sub['flood_depth_rp_min']) * (damage_curves_wind['dam_frac_rp_max'] - damage_curves_wind['dam_frac_rp_min'])\n",
    "                \n",
    "                asset_sub['flood_damage_frac_lower'] = asset_sub['flood_damage_frac']-asset_sub['flood_damage_frac']*0.3\n",
    "                asset_sub['flood_damage_frac_upper'] = asset_sub['flood_damage_frac']+asset_sub['flood_damage_frac']*0.3\n",
    "                \n",
    "                asset_sub['duration_of_flood_days'] = asset_sub.apply(lambda row: np.where(row['frac_flood_dam']<0.001, 0,\n",
    "                                                                    np.where(row['frac_flood_dam']<0.1, 0+(1/30)*((row['frac_flood_dam'])/(0.1)),\n",
    "                                                                    np.where(row['frac_flood_dam']<0.2, 1/30+(3/30-1/30)*((row['frac_flood_dam']-0.1)/(0.2-0.1)),\n",
    "                                                                    np.where(row['frac_flood_dam']<0.3, 3/30+(7/30-3/30)*((row['frac_flood_dam']-0.2)/(0.3-0.2)),\n",
    "                                                                    np.where(row['frac_flood_dam']<0.35, 7/30+(0.25-7/30)*((row['frac_flood_dam']-0.3)/(0.35-0.3)),\n",
    "                                                                    np.where(row['frac_flood_dam']>=0.35, 0.25+(1-0.25)*((row['frac_flood_dam']-0.35)/(0.4-0.35)),1)))))), axis=1)\n",
    "                asset_sub['duration_of_event_flood_upper'] = asset_sub.apply(lambda row: np.where(row['frac_flood_dam_upper']<0.001, 0,\n",
    "                                                                    np.where(row['frac_flood_dam_upper']<0.1, 0+(1/30)*((row['frac_flood_dam_upper'])/(0.1)),\n",
    "                                                                    np.where(row['frac_flood_dam_upper']<0.2, 1/30+(3/30-1/30)*((row['frac_flood_dam_upper']-0.1)/(0.2-0.1)),\n",
    "                                                                    np.where(row['frac_flood_dam_upper']<0.3, 3/30+(7/30-3/30)*((row['frac_flood_dam_upper']-0.2)/(0.3-0.2)),\n",
    "                                                                    np.where(row['frac_flood_dam_upper']<0.35, 7/30+(0.25-7/30)*((row['frac_flood_dam_upper']-0.3)/(0.35-0.3)),\n",
    "                                                                    np.where(row['frac_flood_dam_upper']>=0.35, 0.25+(1-0.25)*((row['frac_flood_dam_upper']-0.35)/(0.4-0.35)),1)))))), axis=1)\n",
    "                asset_sub['duration_of_event_flood_lower'] = asset_sub.apply(lambda row: np.where(row['frac_flood_dam_lower']<0.001, 0,\n",
    "                                                                    np.where(row['frac_flood_dam_lower']<0.1, 0+(1/30)*((row['frac_flood_dam_lower'])/(0.1)),\n",
    "                                                                    np.where(row['frac_flood_dam_lower']<0.2, 1/30+(3/30-1/30)*((row['frac_flood_dam_lower']-0.1)/(0.2-0.1)),\n",
    "                                                                    np.where(row['frac_flood_dam_lower']<0.3, 3/30+(7/30-3/30)*((row['frac_flood_dam_lower']-0.2)/(0.3-0.2)),\n",
    "                                                                    np.where(row['frac_flood_dam_lower']<0.35, 7/30+(0.25-7/30)*((row['frac_flood_dam_lower']-0.3)/(0.35-0.3)),\n",
    "                                                                    np.where(row['frac_flood_dam_lower']>=0.35, 0.25+(1-0.25)*((row['frac_flood_dam_lower']-0.35)/(0.4-0.35)),1)))))), axis=1)\n",
    "                \n",
    "                asset_sub['CDD_flood_asset'] = asset_sub['duration_of_event_days']*num_days_in_month*asset_sub['population_served_by_asset']\n",
    "                asset_sub['CDD_flood_asset_min'] = asset_sub['duration_of_event_days_upper']*num_days_in_month*asset_sub['population_served_by_asset']\n",
    "                asset_sub['CDD_flood_asset_max'] = asset_sub['duration_of_event_days_lower']*num_days_in_month*asset_sub['population_served_by_asset']\n",
    "                system = asset_sub.groupby('system')['CDD_asset'].max().to_frame().reset_index().rename(columns = {'CDD_asset':'CDD_system'})\n",
    "                system['CDD_flood_system_max'] = asset_sub.groupby('system')['CDD_flood_asset_min'].max().to_frame().reset_index()['CDD_flood_asset_min']\n",
    "                system['CDD_flood_system_min'] = asset_sub.groupby('system')['CDD_flood_asset_max'].min().to_frame().reset_index()['CDD_flood_asset_max']\n",
    "                # same as above for wind \n",
    "                \n",
    "                system['CDD_system'] = system[['CDD_flood_asset','CDD_wind_asset']].max(axis=1)\n",
    "                system['CDD_system_max'] = system[['CDD_flood_system_max','CDD_wind_asset_max']].max(axis=1)\n",
    "                system['CDD_system_min'] = system[['CDD_flood_system_min','CDD_wind_asset_min']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RF = # read dataframe of era5 temp and precip, and streamflow per abstraction point:\n",
    "    \n",
    "y_rf = data_RF['Monthly Streamflow'] \n",
    "x_rf = data_RF[['Temperature','Rainfall','Rainfall_lag1','Rainfall_lag2']]\n",
    "x_rf_full = monthly_water_supply_ba[['Temperature','Rainfall','Rainfall_lag1','Rainfall_lag2']]\n",
    "x_rf  = sm.add_constant(x_rf)\n",
    "x_rf_full  = sm.add_constant(x_rf_full)\n",
    "X_train = x_rf.tail(384)\n",
    "y_train = y_rf.tail(384)\n",
    "X_test = x_rf.head(96)\n",
    "y_test = y_rf.head(96)\n",
    "        \n",
    "model_RF = RandomForestRegressor(n_estimators=1000, bootstrap = True,max_features = 'sqrt')\n",
    "model_RF.fit(X_train, y_train)\n",
    "\n",
    "rf_test = model_RF.predict(X_test)\n",
    "r2_test = r2_score(y_test, rf_test)\n",
    "print(r2_test)\n",
    "\n",
    "rf_train = model_RF.predict(x_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = # dataframe of synthetically generated baseline monthly supply per systems, population served and leakage loss rate per system  \n",
    "rcp26 = # dataframe of synthetically generated rcp2.6 monthly supply per systems, population served and leakage loss rate per system  \n",
    "rcp45 = # dataframe of synthetically generated rcp4.5 monthly supply per systems, population served and leakage loss rate per system  \n",
    "rcp85 = # dataframe of synthetically generated rcp8.5 monthly supply per systemsm population served and leakage loss rate per system  \n",
    "for cc in [baseline, rcp26, rcp45, rcp85]:\n",
    "    df_full_pivot_m = cc_dict[cc]\n",
    "    df_full_pivot_m_gb = df_full_pivot_m.groupby(['system'])['supply (m3/month)'].quantile(0.01).to_frame().reset_index().rename(columns = {'supply (m3/month)':'env flow (m3/month)'})\n",
    "\n",
    "    df_full_pivot_m = df_full_pivot_m.merge(df_full_pivot_m_gb, on=['system'])\n",
    "    df_full_pivot_m['demand (m3/month)'] = (consumption_per_cap_per_month_m3)*df_full_pivot_m['population_served_system']\n",
    "    df_full_pivot_m['leakage (m3/month)'] = df_full_pivot_m['demand (m3/month)'] * system_leakage_rate\n",
    "    \n",
    "    df_full_pivot_m['drought threshold (m3/month)'] = (df_full_pivot_m['demand (m3/month)']+df_full_pivot_m['leakage (m3/month)'])\n",
    "    df_full_pivot_m['drought threshold (m3/month)_min'] = df_full_pivot_m['drought threshold (m3/month)']-df_full_pivot_m['drought threshold (m3/month)']*0.3\n",
    "    df_full_pivot_m['drought threshold (m3/month)_max'] = df_full_pivot_m['drought threshold (m3/month)']+df_full_pivot_m['drought threshold (m3/month)']*0.3\n",
    "\n",
    "    df_full_pivot_m['balance (m3/month)'] = df_full_pivot_m['supply (m3/month)'] + df_full_pivot_m['storage increase (m3/month)'] - df_full_pivot_m['drought threshold (m3/month)']\n",
    "    df_full_pivot_m['deficit (m3/month)'] = np.where(df_full_pivot_m['balance (m3/month)']<0,df_full_pivot_m['balance (m3/month)']*-1,0)\n",
    "    df_full_pivot_m['frac'] = (df_full_pivot_m['deficit (m3/month)']/df_full_pivot_m['demand (m3/month)'])\n",
    "    df_full_pivot_m['frac'] = np.where(df_full_pivot_m['frac']>1, 1, df_full_pivot_m['frac'])\n",
    "\n",
    "    df_full_pivot_m['balance (m3/month)_min'] = df_full_pivot_m['supply (m3/month)'] + df_full_pivot_m['storage increase (m3/month)'] - df_full_pivot_m['drought threshold (m3/month)_max']\n",
    "    df_full_pivot_m['deficit (m3/month)_min'] = np.where(df_full_pivot_m['balance (m3/month)_min']<0,df_full_pivot_m['balance (m3/month)_min']*-1,0)\n",
    "    df_full_pivot_m['frac_min'] = (df_full_pivot_m['deficit (m3/month)_min']/df_full_pivot_m['demand (m3/month)'])\n",
    "    df_full_pivot_m['frac_min'] = np.where(df_full_pivot_m['frac_min']>1, 1, df_full_pivot_m['frac_min'])\n",
    "\n",
    "    df_full_pivot_m['balance (m3/month)_max'] = df_full_pivot_m['supply (m3/month)'] + df_full_pivot_m['storage increase (m3/month)'] - df_full_pivot_m['drought threshold (m3/month)_min']\n",
    "    df_full_pivot_m['deficit (m3/month)_max'] = np.where(df_full_pivot_m['balance (m3/month)_max']<0,df_full_pivot_m['balance (m3/month)_max']*-1,0)\n",
    "    df_full_pivot_m['frac_max'] = (df_full_pivot_m['deficit (m3/month)_max']/df_full_pivot_m['demand (m3/month)'])\n",
    "    df_full_pivot_m['frac_max'] = np.where(df_full_pivot_m['frac_max']>1, 1, df_full_pivot_m['frac_max'])\n",
    "\n",
    "    df_full_pivot_m['CDD'] = df_full_pivot_m['frac']*df_full_pivot_m['population_served_system']*num_days_in_month\n",
    "    df_full_pivot_m['CDD_min'] = df_full_pivot_m['frac_min']*df_full_pivot_m['population_served_system']*num_days_in_month\n",
    "    df_full_pivot_m['CDD_max'] = df_full_pivot_m['frac_max']*df_full_pivot_m['population_served_system']*num_days_in_month\n",
    "    \n",
    "    df_full_pivot_m_gb = df_full_pivot_m_full.groupby(['system','cc','year','synth'])['CDD'].sum().to_frame().reset_index()\n",
    "    df_full_pivot_m_gb['CDD_min'] = df_full_pivot_m_full.groupby(['system','cc','year','synth'])['CDD_min'].sum().to_frame().reset_index()['CDD_min']\n",
    "    df_full_pivot_m_gb['CDD_max'] = df_full_pivot_m_full.groupby(['system','cc','year','synth'])['CDD_max'].sum().to_frame().reset_index()['CDD_max']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System level aed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_pivot_m_full = # dataframe of CDD per asset damage / water shortage event\n",
    "\n",
    "df_full_pivot_m_gb_aed = df_full_pivot_m_gb.groupby(['system','cc'])['CDD'].apply(list).to_frame().reset_index()\n",
    "df_full_pivot_m_gb_aed_min = df_full_pivot_m_gb.groupby(['system','cc'])['CDD_min'].apply(list).to_frame().reset_index()\n",
    "df_full_pivot_m_gb_aed_max = df_full_pivot_m_gb.groupby(['system','cc'])['CDD_max'].apply(list).to_frame().reset_index()\n",
    "aep_list = []\n",
    "for i in np.linspace(1,1000,1000):\n",
    "    aep_list.append(1/(1000/i))\n",
    "\n",
    "df_full_pivot_m_gb_aed['aep_list'] = [aep_list]*df_full_pivot_m_gb_aed.shape[0]\n",
    "df_full_pivot_m_gb_aed['aed'] = df_full_pivot_m_gb_aed.apply(lambda row: integrate.trapz(sorted(row['CDD_system'], reverse=True), row['aep_list']), axis=1)\n",
    "\n",
    "df_full_pivot_m_gb_aed_min['aep_list'] = [aep_list]*df_full_pivot_m_gb_aed_min.shape[0]\n",
    "df_full_pivot_m_gb_aed_min['aed_min'] = df_full_pivot_m_gb_aed_min.apply(lambda row: integrate.trapz(sorted(row['CDD_system_min'], reverse=True), row['aep_list']), axis=1)\n",
    "\n",
    "df_full_pivot_m_gb_aed_max['aep_list'] = [aep_list]*df_full_pivot_m_gb_aed_max.shape[0]\n",
    "df_full_pivot_m_gb_aed_max['aed_max'] = df_full_pivot_m_gb_aed_max.apply(lambda row: integrate.trapz(sorted(row['CDD_system_max'], reverse=True), row['aep_list']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_service_areas = # geodataframe of NWC potable systems\n",
    "\n",
    "system_service_areas_merge_ad = # dataframe of annual expected asset damage CDD per climate scenario \n",
    "system_service_areas_merge_ad = pd.merge(system_service_areas[['system','geometry']], system_service_areas_merge_fld[['system','aed_total_cost','cc']], on='system')\n",
    "system_service_areas_merge_ad = gpd.GeoDataFrame(system_service_areas_merge_fld,crs=\"EPSG:3448\",geometry=system_service_areas_merge_fld['geometry'])\n",
    "system_service_areas_merge_ad['aed (thousands)'] = system_service_areas_merge_ad['aed']/1e3\n",
    "\n",
    "system_service_areas_merge_ws = # dataframe of  annual expected water shortage CDD per climate scenario \n",
    "system_service_areas_merge_ws = pd.merge(system_service_areas[['system','geometry']], system_service_areas_merge_win[['system','aed_total_cost','cc']], on='system')\n",
    "system_service_areas_merge_ws = gpd.GeoDataFrame(system_service_areas_merge_win,crs=\"EPSG:3448\",geometry=system_service_areas_merge_win['geometry'])\n",
    "system_service_areas_merge_ws['aed (thousands)'] = system_service_areas_merge_ws['aed']/1e3\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17,3.5), linewidth=0.5) ### 4 grid per return period       \n",
    "island.plot(ax=ax[0], color='none', edgecolor='black', linewidth=0.5)\n",
    "system_service_areas_merge_baseline = system_service_areas_merge_ws[system_service_areas_merge_ws['cc']=='baseline'].drop_duplicates()\n",
    "system_service_areas_merge_baseline.plot(ax=ax[0], column = 'aed (thousands)', cmap='Reds', vmin = min(system_service_areas_merge_baseline['aed (thousands)'].min(),system_service_areas_merge_baseline['aed (thousands)'].min()), \n",
    "                                                                                                vmax = max(system_service_areas_merge_baseline['aed (thousands)'].quantile(0.95),system_service_areas_merge_baseline['aed (thousands)'].quantile(0.95)), \n",
    "                                                                                                edgecolor='k', alpha=0.5, linewidth=0.5, legend=True, legend_kwds = {'label':'Annual expected CDD (thousands)'}) \n",
    "ax[0].set_ylim(600000,720000) \n",
    "ax[0].set_xlim(600000,850000)    \n",
    "ax[0].set_title('Baseline Customer Disruption Days caused by water shortage')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "\n",
    "island.plot(ax=ax[1], color='none', edgecolor='black', linewidth=0.5)\n",
    "system_service_areas_merge_baseline = system_service_areas_merge_ad[system_service_areas_merge_ad['cc']=='baseline'].drop_duplicates()\n",
    "system_service_areas_merge_baseline.plot(ax=ax[1], column = 'aed_total_cost', cmap='Blues', vmin = min(system_service_areas_merge_baseline['aed (thousands)'].min(),system_service_areas_merge_baseline['aed (thousands)'].min()), \n",
    "                                                                                                vmax = max(system_service_areas_merge_baseline['aed (thousands)'].quantile(0.95),system_service_areas_merge_baseline['aed (thousands)'].quantile(0.95)), \n",
    "                                                                                                edgecolor='k', alpha=0.5, linewidth=0.5, legend=True, legend_kwds = {'label':'Annual expected CDD (thousands)'})\n",
    "ax[1].set_ylim(600000,720000) \n",
    "ax[1].set_xlim(600000,850000)    \n",
    "ax[1].set_title('Baseline Customer Disruption Days caused by asset damage')\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility total return period curve (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = # dataframe of CDD caused by each asset damage / water shortage event per climate scenario\n",
    "\n",
    "cc_dict = {'baseline':'lightgrey','rcp26':'lightpink','rcp45':'orange','baseline':'darkred'}\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,5), sharey=True)  \n",
    "for cc in cc_dict:    \n",
    "    event_df_gb_ba = event_df[event_df['cc']=='baseline']\n",
    "    \n",
    "    event_df_gb = event_df_ba.groupby(['cc','event'])['CDD_system'].sum().to_frame().reset_index()\n",
    "    event_df_gb['CDD_system_max'] = event_df_ba.groupby(['cc','event'])['CDD_system_max'].sum().to_frame().reset_index()['CDD_system_max']\n",
    "    event_df_gb['CDD_system_min'] = event_df_ba.groupby(['cc','event'])['CDD_system_min'].sum().to_frame().reset_index()['CDD_system_min']\n",
    "    \n",
    "    event_df_gb = event_df_gb.sort_values(by=['CDD_system'], ascending=False)\n",
    "    num_years = 1e3\n",
    "    num_events = event_df_gb.shape[0]                              \n",
    "    event_df_gb['rank'] = np.linspace(1, num_events+1, num_events)\n",
    "    event_df_gb['rp'] = 1/(event_df_gb['rank']/num_years)\n",
    "\n",
    "    ax.scatter(event_df_gb['rp'],(event_df_gb['CDD_system']/1e6),c=cc_dict[cc], s=25, edgecolor='k', linewidths=0.05, alpha=0.5)    \n",
    "    ax.fill_between(event_df_gb['rp'],event_df_gb['CDD_system_max']/1e6,event_df_gb['CDD_system_min']/1e6,color=cc_dict[cc], alpha=0.4) \n",
    "    \n",
    "baseline_patch = mpatches.Patch(color='lightgrey', label='baseline')\n",
    "scen_26_patch = mpatches.Patch(color='orange', label='RCP26')\n",
    "scen_45_patch = mpatches.Patch(color='lightpink', label='RCP45')\n",
    "scen_85_patch = mpatches.Patch(color='darkred', label='RCP85')\n",
    "\n",
    "ax.legend(handles=[baseline_patch,scen_26_patch,scen_45_patch,scen_85_patch])\n",
    "ax.grid(which='major',linestyle='-', linewidth='0.5', color='silver')\n",
    "ax.grid(which='minor',linestyle='-', linewidth='0.2', color='silver')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1,1e3)\n",
    "ax.set_xlabel('Return Period (years)')    \n",
    "ax.set_ylim(1,event_df_gb['CDD_system_max'].max())\n",
    "ax.set_ylabel('Customer Disruption Days \\n (millions)')\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(0,event_df_gb['CDD_system_max'].max()/(num_utility_customers*num_days_in_year))\n",
    "ax2.set_ylabel('Customer Disruption Days \\n (% of maximum annual disruption of full customer-base)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5 (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = # dataframe of CDD caused by each asset damage / water shortage event per climate scenario\n",
    "\n",
    "parish_groupby = event_df.groupby(['cc','PARISH','event'])['CDD_system'].sum().to_frame().reset_index()\n",
    "parish_groupby['parish_population'] = event_df.groupby(['cc','PARISH','event'])['population_served_system'].sum().to_frame().reset_index()['parish_population']\n",
    "parish_groupby = parish_groupby.merge(asset_criticality_parish, on='PARISH')\n",
    "parish_groupby['frac_parish_disrupted'] = parish_groupby['CDD_system']/parish_groupby['parish_population']\n",
    "\n",
    "parish_y = []\n",
    "parish_x = []\n",
    "regression = []\n",
    "for x in parish_groupby['PARISH'].drop_duplicates().to_list():\n",
    "    iter_x = parish_groupby[parish_groupby['PARISH'] == x]\n",
    "    iter_x = iter_x[iter_x['frac_parish_disrupted']>0]\n",
    "    for y in parish_groupby['PARISH'].drop_duplicates().to_list(): \n",
    "        iter_y = parish_groupby[parish_groupby['PARISH'] == y]\n",
    "        iter_y = iter_y[iter_y['parish_frac']>0]\n",
    "        merged = pd.merge(iter_x, iter_y, on='index')\n",
    "        parish_x.append(x)\n",
    "        parish_y.append(y)\n",
    "        r = np.corrcoef(merged['parish_frac_x'], merged['parish_frac_y'])[1, 0]\n",
    "        regression.append(r)\n",
    "        \n",
    "widespread_df = pd.DataFrame({'parish_x':parish_x, 'parish_y':parish_y, 'regression':regression})\n",
    "     \n",
    "widespread_df_pivot = widespread_df.pivot(index='parish_x', columns='parish_y', values='regression')\n",
    "widespread_df_pivot = widespread_df_pivot.fillna(0)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,8), 'font.sans-serif': ['Arial'], \n",
    "            'axes.spines.left': True,\n",
    "            'axes.spines.bottom': True,\n",
    "            'axes.spines.right': True,\n",
    "            'axes.spines.top': True})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "mask = np.zeros_like(widespread_df_pivot,dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,6), linewidth=0.5) ### 4 grid per return period       \n",
    "ax = sns.heatmap(widespread_df_pivot, mask = mask, cmap = 'Reds',square = True, vmin = 0, vmax = 1)\n",
    "plt.xlabel('Parish')\n",
    "plt.ylabel('Parish')\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4 (bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = # read dataframe of  asset damage and water shortage-related annual expected CDD per asset type\n",
    "\n",
    "aran = np.arange(4) \n",
    "width = 0.3\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,7))\n",
    "\n",
    "baseline_ad_w = [df[(df['disruption type']=='asset damage')&(df['haz']=='wind')]['baseline'].to_list()[0],\n",
    "                df[(df['disruption type']=='asset damage')&(df['haz']=='wind')]['rcp26'].to_list()[0],\n",
    "                df[(df['disruption type']=='asset damage')&(df['haz']=='wind')]['rcp45'].to_list()[0],\n",
    "                df[(df['disruption type']=='asset damage')&(df['haz']=='wind')]['rcp85'].to_list()[0]]\n",
    "baseline_ad_f = [df[(df['disruption type']=='asset damage')&(df['haz']=='flood')]['baseline'].to_list()[0],\n",
    "                df[(df['disruption type']=='asset damage')&(df['haz']=='flood')]['rcp26'].to_list()[0],\n",
    "                df[(df['disruption type']=='asset damage')&(df['haz']=='flood')]['rcp45'].to_list()[0],\n",
    "                df[(df['disruption type']=='asset damage')&(df['haz']=='flood')]['rcp85'].to_list()[0]]\n",
    "rects1 = ax.bar(aran-0.15, baseline_ad_w, width, label='Wind-induced asset damage', color='midnightblue') #yerr = baseline_ad_w_yerr, \n",
    "rects1_2 = ax.bar(aran-0.15, baseline_ad_f, width, bottom = baseline_ad_w, label='Flood inundation-induced asset damage', color='lightblue')\n",
    "\n",
    "baseline_dr = [df[(df['disruption type']=='water shortage')&(df['haz']=='drought')]['baseline'].to_list()[0],\n",
    "                df[(df['disruption type']=='water shortage')&(df['haz']=='drought')]['rcp26'].to_list()[0],\n",
    "                df[(df['disruption type']=='water shortage')&(df['haz']=='drought')]['rcp45'].to_list()[0],\n",
    "                df[(df['disruption type']=='water shortage')&(df['haz']=='drought')]['rcp85'].to_list()[0]]\n",
    "\n",
    "rects2 = ax.bar(aran+0.15, baseline_dr, width, label='Water shortage', color='darkred') # yerryerr = baseline_dr_yerr, \n",
    "ax.set_ylabel('Annual Expected CDD (millions)')\n",
    "ax.set_title('Customer Disruption Days per climate change scenario (millions)')\n",
    "ax.set_xticks([0, 1, 2, 3, 4])\n",
    "ax.set_xticklabels(['Baseline', 'RCP2.6', 'RCP4.5', 'RCP8.5', ''])\n",
    "ax.set_xlim(right=3.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
